{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraped article 1/500\n",
      "Scraped article 2/500\n",
      "Scraped article 3/500\n",
      "Scraped article 4/500\n",
      "Scraped article 5/500\n",
      "Scraped article 6/500\n",
      "Scraped article 7/500\n",
      "Scraped article 8/500\n",
      "Scraped article 9/500\n",
      "Scraped article 10/500\n",
      "Scraped article 11/500\n",
      "Scraped article 12/500\n",
      "Scraped article 13/500\n",
      "Scraped article 14/500\n",
      "Scraped article 15/500\n",
      "Scraped article 16/500\n",
      "Scraped article 17/500\n",
      "Scraped article 18/500\n",
      "Scraped article 19/500\n",
      "Scraped article 20/500\n",
      "Scraped article 21/500\n",
      "Scraped article 22/500\n",
      "Scraped article 23/500\n",
      "Scraped article 24/500\n",
      "Scraped article 25/500\n",
      "Scraped article 26/500\n",
      "Scraped article 27/500\n",
      "Scraped article 28/500\n",
      "Scraped article 29/500\n",
      "Scraped article 30/500\n",
      "Scraped article 31/500\n",
      "Scraping page 2...\n",
      "Scraped article 32/500\n",
      "Scraped article 33/500\n",
      "Scraped article 34/500\n",
      "Scraped article 35/500\n",
      "Scraped article 36/500\n",
      "Scraped article 37/500\n",
      "Scraped article 38/500\n",
      "Scraped article 39/500\n",
      "Scraped article 40/500\n",
      "Scraped article 41/500\n",
      "Scraped article 42/500\n",
      "Scraped article 43/500\n",
      "Scraped article 44/500\n",
      "Scraped article 45/500\n",
      "Scraped article 46/500\n",
      "Scraping page 3...\n",
      "Scraped article 47/500\n",
      "Scraped article 48/500\n",
      "Scraped article 49/500\n",
      "Scraped article 50/500\n",
      "Scraped article 51/500\n",
      "Scraped article 52/500\n",
      "Scraped article 53/500\n",
      "Scraped article 54/500\n",
      "Scraped article 55/500\n",
      "Scraped article 56/500\n",
      "Scraped article 57/500\n",
      "Scraped article 58/500\n",
      "Scraped article 59/500\n",
      "Scraped article 60/500\n",
      "Scraped article 61/500\n",
      "Scraping page 4...\n",
      "Scraped article 62/500\n",
      "Scraped article 63/500\n",
      "Scraped article 64/500\n",
      "Scraped article 65/500\n",
      "Scraped article 66/500\n",
      "Scraped article 67/500\n",
      "Scraped article 68/500\n",
      "Scraped article 69/500\n",
      "Scraped article 70/500\n",
      "Scraped article 71/500\n",
      "Scraped article 72/500\n",
      "Scraped article 73/500\n",
      "Scraped article 74/500\n",
      "Scraped article 75/500\n",
      "Scraped article 76/500\n",
      "Scraping page 5...\n",
      "Scraped article 77/500\n",
      "Scraped article 78/500\n",
      "Scraped article 79/500\n",
      "Scraped article 80/500\n",
      "Scraped article 81/500\n",
      "Scraped article 82/500\n",
      "Scraped article 83/500\n",
      "Scraped article 84/500\n",
      "Scraped article 85/500\n",
      "Scraped article 86/500\n",
      "Scraped article 87/500\n",
      "Scraped article 88/500\n",
      "Scraped article 89/500\n",
      "Scraped article 90/500\n",
      "Scraped article 91/500\n",
      "Scraping page 6...\n",
      "Scraped article 92/500\n",
      "Scraped article 93/500\n",
      "Scraped article 94/500\n",
      "Scraped article 95/500\n",
      "Scraped article 96/500\n",
      "Scraped article 97/500\n",
      "Scraped article 98/500\n",
      "Scraped article 99/500\n",
      "Scraped article 100/500\n",
      "Scraped article 101/500\n",
      "Scraped article 102/500\n",
      "Scraped article 103/500\n",
      "Scraped article 104/500\n",
      "Scraped article 105/500\n",
      "Scraped article 106/500\n",
      "Scraping page 7...\n",
      "Scraped article 107/500\n",
      "Scraped article 108/500\n",
      "Scraped article 109/500\n",
      "Scraped article 110/500\n",
      "Scraped article 111/500\n",
      "Scraped article 112/500\n",
      "Scraped article 113/500\n",
      "Scraped article 114/500\n",
      "Scraped article 115/500\n",
      "Scraped article 116/500\n",
      "Scraped article 117/500\n",
      "Scraped article 118/500\n",
      "Scraped article 119/500\n",
      "Scraped article 120/500\n",
      "Scraped article 121/500\n",
      "Scraping page 8...\n",
      "Scraped article 122/500\n",
      "Scraped article 123/500\n",
      "Scraped article 124/500\n",
      "Scraped article 125/500\n",
      "Scraped article 126/500\n",
      "Scraped article 127/500\n",
      "Scraped article 128/500\n",
      "Scraped article 129/500\n",
      "Scraped article 130/500\n",
      "Scraped article 131/500\n",
      "Scraped article 132/500\n",
      "Scraped article 133/500\n",
      "Scraped article 134/500\n",
      "Scraped article 135/500\n",
      "Scraped article 136/500\n",
      "Scraping page 9...\n",
      "Scraped article 137/500\n",
      "Scraped article 138/500\n",
      "Scraped article 139/500\n",
      "Scraped article 140/500\n",
      "Scraped article 141/500\n",
      "Scraped article 142/500\n",
      "Scraped article 143/500\n",
      "Scraped article 144/500\n",
      "Scraped article 145/500\n",
      "Scraped article 146/500\n",
      "Scraped article 147/500\n",
      "Scraped article 148/500\n",
      "Scraped article 149/500\n",
      "Scraped article 150/500\n",
      "Scraped article 151/500\n",
      "Scraping page 10...\n",
      "Scraped article 152/500\n",
      "Scraped article 153/500\n",
      "Scraped article 154/500\n",
      "Scraped article 155/500\n",
      "Scraped article 156/500\n",
      "Scraped article 157/500\n",
      "Scraped article 158/500\n",
      "Scraped article 159/500\n",
      "Scraped article 160/500\n",
      "Scraped article 161/500\n",
      "Scraped article 162/500\n",
      "Scraped article 163/500\n",
      "Scraped article 164/500\n",
      "Scraped article 165/500\n",
      "Scraped article 166/500\n",
      "Scraping page 11...\n",
      "Scraped article 167/500\n",
      "Scraped article 168/500\n",
      "Scraped article 169/500\n",
      "Scraped article 170/500\n",
      "Scraped article 171/500\n",
      "Scraped article 172/500\n",
      "Scraped article 173/500\n",
      "Scraped article 174/500\n",
      "Scraped article 175/500\n",
      "Scraped article 176/500\n",
      "Scraped article 177/500\n",
      "Scraped article 178/500\n",
      "Scraped article 179/500\n",
      "Scraped article 180/500\n",
      "Scraped article 181/500\n",
      "Scraping page 12...\n",
      "Scraped article 182/500\n",
      "Scraped article 183/500\n",
      "Scraped article 184/500\n",
      "Scraped article 185/500\n",
      "Scraped article 186/500\n",
      "Scraped article 187/500\n",
      "Scraped article 188/500\n",
      "Scraped article 189/500\n",
      "Scraped article 190/500\n",
      "Scraped article 191/500\n",
      "Scraped article 192/500\n",
      "Scraped article 193/500\n",
      "Scraped article 194/500\n",
      "Scraped article 195/500\n",
      "Scraped article 196/500\n",
      "Scraping page 13...\n",
      "Scraped article 197/500\n",
      "Scraped article 198/500\n",
      "Scraped article 199/500\n",
      "Scraped article 200/500\n",
      "Scraped article 201/500\n",
      "Scraped article 202/500\n",
      "Scraped article 203/500\n",
      "Scraped article 204/500\n",
      "Scraped article 205/500\n",
      "Scraped article 206/500\n",
      "Scraped article 207/500\n",
      "Scraped article 208/500\n",
      "Scraped article 209/500\n",
      "Scraped article 210/500\n",
      "Scraped article 211/500\n",
      "Scraping page 14...\n",
      "Scraped article 212/500\n",
      "Scraped article 213/500\n",
      "Scraped article 214/500\n",
      "Scraped article 215/500\n",
      "Scraped article 216/500\n",
      "Scraped article 217/500\n",
      "Scraped article 218/500\n",
      "Scraped article 219/500\n",
      "Scraped article 220/500\n",
      "Scraped article 221/500\n",
      "Scraped article 222/500\n",
      "Scraped article 223/500\n",
      "Scraped article 224/500\n",
      "Scraped article 225/500\n",
      "Scraped article 226/500\n",
      "Scraping page 15...\n",
      "Scraped article 227/500\n",
      "Scraped article 228/500\n",
      "Scraped article 229/500\n",
      "Scraped article 230/500\n",
      "Scraped article 231/500\n",
      "Scraped article 232/500\n",
      "Scraped article 233/500\n",
      "Scraped article 234/500\n",
      "Scraped article 235/500\n",
      "Scraped article 236/500\n",
      "Scraped article 237/500\n",
      "Scraped article 238/500\n",
      "Scraped article 239/500\n",
      "Scraped article 240/500\n",
      "Scraped article 241/500\n",
      "Scraping page 16...\n",
      "Scraped article 242/500\n",
      "Scraped article 243/500\n",
      "Scraped article 244/500\n",
      "Scraped article 245/500\n",
      "Scraped article 246/500\n",
      "Scraped article 247/500\n",
      "Scraped article 248/500\n",
      "Scraped article 249/500\n",
      "Scraped article 250/500\n",
      "Scraped article 251/500\n",
      "Scraped article 252/500\n",
      "Scraped article 253/500\n",
      "Scraped article 254/500\n",
      "Scraped article 255/500\n",
      "Scraped article 256/500\n",
      "Scraping page 17...\n",
      "Scraped article 257/500\n",
      "Scraped article 258/500\n",
      "Scraped article 259/500\n",
      "Scraped article 260/500\n",
      "Scraped article 261/500\n",
      "Scraped article 262/500\n",
      "Scraped article 263/500\n",
      "Scraped article 264/500\n",
      "Scraped article 265/500\n",
      "Scraped article 266/500\n",
      "Scraped article 267/500\n",
      "Scraped article 268/500\n",
      "Scraped article 269/500\n",
      "Scraped article 270/500\n",
      "Scraped article 271/500\n",
      "Scraping page 18...\n",
      "Scraped article 272/500\n",
      "Scraped article 273/500\n",
      "Scraped article 274/500\n",
      "Scraped article 275/500\n",
      "Scraped article 276/500\n",
      "Scraped article 277/500\n",
      "Scraped article 278/500\n",
      "Scraped article 279/500\n",
      "Scraped article 280/500\n",
      "Scraped article 281/500\n",
      "Scraped article 282/500\n",
      "Scraped article 283/500\n",
      "Scraped article 284/500\n",
      "Scraped article 285/500\n",
      "Scraped article 286/500\n",
      "Scraping page 19...\n",
      "Scraped article 287/500\n",
      "Scraped article 288/500\n",
      "Scraped article 289/500\n",
      "Scraped article 290/500\n",
      "Scraped article 291/500\n",
      "Scraped article 292/500\n",
      "Scraped article 293/500\n",
      "Scraped article 294/500\n",
      "Scraped article 295/500\n",
      "Scraped article 296/500\n",
      "Scraped article 297/500\n",
      "Scraped article 298/500\n",
      "Scraped article 299/500\n",
      "Scraped article 300/500\n",
      "Scraped article 301/500\n",
      "Scraping page 20...\n",
      "Scraped article 302/500\n",
      "Scraped article 303/500\n",
      "Scraped article 304/500\n",
      "Scraped article 305/500\n",
      "Scraped article 306/500\n",
      "Scraped article 307/500\n",
      "Scraped article 308/500\n",
      "Scraped article 309/500\n",
      "Scraped article 310/500\n",
      "Scraped article 311/500\n",
      "Scraped article 312/500\n",
      "Scraped article 313/500\n",
      "Scraped article 314/500\n",
      "Scraped article 315/500\n",
      "Scraped article 316/500\n",
      "Scraping page 21...\n",
      "Scraped article 317/500\n",
      "Scraped article 318/500\n",
      "Scraped article 319/500\n",
      "Scraped article 320/500\n",
      "Scraped article 321/500\n",
      "Scraped article 322/500\n",
      "Scraped article 323/500\n",
      "Scraped article 324/500\n",
      "Scraped article 325/500\n",
      "Scraped article 326/500\n",
      "Scraped article 327/500\n",
      "Scraped article 328/500\n",
      "Scraped article 329/500\n",
      "Scraped article 330/500\n",
      "Scraped article 331/500\n",
      "Scraping page 22...\n",
      "Scraped article 332/500\n",
      "Scraped article 333/500\n",
      "Scraped article 334/500\n",
      "Scraped article 335/500\n",
      "Scraped article 336/500\n",
      "Scraped article 337/500\n",
      "Scraped article 338/500\n",
      "Scraped article 339/500\n",
      "Scraped article 340/500\n",
      "Scraped article 341/500\n",
      "Scraped article 342/500\n",
      "Scraped article 343/500\n",
      "Scraped article 344/500\n",
      "Scraped article 345/500\n",
      "Scraped article 346/500\n",
      "Scraping page 23...\n",
      "Scraped article 347/500\n",
      "Scraped article 348/500\n",
      "Scraped article 349/500\n",
      "Scraped article 350/500\n",
      "Scraped article 351/500\n",
      "Scraped article 352/500\n",
      "Scraped article 353/500\n",
      "Scraped article 354/500\n",
      "Scraped article 355/500\n",
      "Scraped article 356/500\n",
      "Scraped article 357/500\n",
      "Scraped article 358/500\n",
      "Scraped article 359/500\n",
      "Scraped article 360/500\n",
      "Scraped article 361/500\n",
      "Scraped article 362/500\n",
      "Scraping page 24...\n",
      "Scraped article 363/500\n",
      "Scraped article 364/500\n",
      "Scraped article 365/500\n",
      "Scraped article 366/500\n",
      "Scraped article 367/500\n",
      "Scraped article 368/500\n",
      "Scraped article 369/500\n",
      "Scraped article 370/500\n",
      "Scraped article 371/500\n",
      "Scraped article 372/500\n",
      "Scraped article 373/500\n",
      "Scraped article 374/500\n",
      "Scraped article 375/500\n",
      "Scraped article 376/500\n",
      "Scraped article 377/500\n",
      "Scraping page 25...\n",
      "Scraped article 378/500\n",
      "Scraped article 379/500\n",
      "Scraped article 380/500\n",
      "Scraped article 381/500\n",
      "Scraped article 382/500\n",
      "Scraped article 383/500\n",
      "Scraped article 384/500\n",
      "Scraped article 385/500\n",
      "Scraped article 386/500\n",
      "Scraped article 387/500\n",
      "Scraped article 388/500\n",
      "Scraped article 389/500\n",
      "Scraped article 390/500\n",
      "Scraped article 391/500\n",
      "Scraped article 392/500\n",
      "Scraping page 26...\n",
      "Scraped article 393/500\n",
      "Scraped article 394/500\n",
      "Scraped article 395/500\n",
      "Scraped article 396/500\n",
      "Scraped article 397/500\n",
      "Scraped article 398/500\n",
      "Scraped article 399/500\n",
      "Scraped article 400/500\n",
      "Scraped article 401/500\n",
      "Scraped article 402/500\n",
      "Scraped article 403/500\n",
      "Scraped article 404/500\n",
      "Scraped article 405/500\n",
      "Scraped article 406/500\n",
      "Scraped article 407/500\n",
      "Scraped article 408/500\n",
      "Scraped article 409/500\n",
      "Scraping page 27...\n",
      "Scraped article 410/500\n",
      "Scraped article 411/500\n",
      "Scraped article 412/500\n",
      "Scraped article 413/500\n",
      "Scraped article 414/500\n",
      "Scraped article 415/500\n",
      "Scraped article 416/500\n",
      "Scraped article 417/500\n",
      "Scraped article 418/500\n",
      "Scraped article 419/500\n",
      "Scraped article 420/500\n",
      "Scraped article 421/500\n",
      "Scraped article 422/500\n",
      "Scraped article 423/500\n",
      "Scraped article 424/500\n",
      "Scraping page 28...\n",
      "Scraped article 425/500\n",
      "Scraped article 426/500\n",
      "Scraped article 427/500\n",
      "Scraped article 428/500\n",
      "Scraped article 429/500\n",
      "Scraped article 430/500\n",
      "Scraped article 431/500\n",
      "Scraped article 432/500\n",
      "Scraped article 433/500\n",
      "Scraped article 434/500\n",
      "Scraped article 435/500\n",
      "Scraped article 436/500\n",
      "Scraped article 437/500\n",
      "Scraped article 438/500\n",
      "Scraped article 439/500\n",
      "Scraping page 29...\n",
      "Scraped article 440/500\n",
      "Scraped article 441/500\n",
      "Scraped article 442/500\n",
      "Scraped article 443/500\n",
      "Scraped article 444/500\n",
      "Scraped article 445/500\n",
      "Scraped article 446/500\n",
      "Scraped article 447/500\n",
      "Scraped article 448/500\n",
      "Scraped article 449/500\n",
      "Scraped article 450/500\n",
      "Scraped article 451/500\n",
      "Scraped article 452/500\n",
      "Scraped article 453/500\n",
      "Scraped article 454/500\n",
      "Scraping page 30...\n",
      "Scraped article 455/500\n",
      "Scraped article 456/500\n",
      "Scraped article 457/500\n",
      "Scraped article 458/500\n",
      "Scraped article 459/500\n",
      "Scraped article 460/500\n",
      "Scraped article 461/500\n",
      "Scraped article 462/500\n",
      "Scraped article 463/500\n",
      "Scraped article 464/500\n",
      "Scraped article 465/500\n",
      "Scraped article 466/500\n",
      "Scraped article 467/500\n",
      "Scraped article 468/500\n",
      "Scraped article 469/500\n",
      "Scraping page 31...\n",
      "Scraped article 470/500\n",
      "Scraped article 471/500\n",
      "Scraped article 472/500\n",
      "Scraped article 473/500\n",
      "Scraped article 474/500\n",
      "Scraped article 475/500\n",
      "Scraped article 476/500\n",
      "Scraped article 477/500\n",
      "Scraped article 478/500\n",
      "Scraped article 479/500\n",
      "Scraped article 480/500\n",
      "Scraped article 481/500\n",
      "Scraped article 482/500\n",
      "Scraped article 483/500\n",
      "Scraped article 484/500\n",
      "Scraping page 32...\n",
      "Scraped article 485/500\n",
      "Scraped article 486/500\n",
      "Scraped article 487/500\n",
      "Scraped article 488/500\n",
      "Scraped article 489/500\n",
      "Scraped article 490/500\n",
      "Scraped article 491/500\n",
      "Scraped article 492/500\n",
      "Scraped article 493/500\n",
      "Scraped article 494/500\n",
      "Scraped article 495/500\n",
      "Scraped article 496/500\n",
      "Scraped article 497/500\n",
      "Scraped article 498/500\n",
      "Scraped article 499/500\n",
      "Scraped article 500/500\n",
      "\n",
      "Scraped 500 total articles\n",
      "Saved 499 unique articles to: D:\\Web Scrapping Project\\efsyn_articles\\efsyn_articles_20241031_141356.json\n",
      "Removed 1 duplicates\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional, Set\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "class EfsynScraper:\n",
    "    def __init__(self, base_url: str = \"https://www.efsyn.gr\"):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        self.seen_urls = set()  # Track processed URLs to avoid duplicates\n",
    "        self.article_count = 0  # Track total articles processed\n",
    "        self.MAX_ARTICLES = 500\n",
    "\n",
    "    def _get_soup(self, url: str) -> BeautifulSoup:\n",
    "        \"\"\"Get BeautifulSoup object from URL.\"\"\"\n",
    "        response = self.session.get(url)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    def _parse_date(self, date_element) -> str:\n",
    "        \"\"\"Parse date from time element.\"\"\"\n",
    "        if not date_element:\n",
    "            return \"\"\n",
    "        datetime_str = date_element.get('datetime', '')\n",
    "        return datetime_str\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean text content.\"\"\"\n",
    "        return ' '.join(text.strip().split())\n",
    "\n",
    "    def _extract_article_content(self, soup: BeautifulSoup) -> str:\n",
    "        \"\"\"Extract article content, removing ads and scripts.\"\"\"\n",
    "        article_body = soup.find('div', class_='article__body')\n",
    "        if not article_body:\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove all script tags and ad containers\n",
    "        for element in article_body.find_all(['script', 'div'], class_='adv'):\n",
    "            element.decompose()\n",
    "        \n",
    "        # Extract text from remaining paragraphs\n",
    "        paragraphs = article_body.find_all('p')\n",
    "        return ' '.join(self._clean_text(p.get_text()) for p in paragraphs)\n",
    "\n",
    "    def _get_author(self, soup: BeautifulSoup) -> str:\n",
    "        \"\"\"Extract author name.\"\"\"\n",
    "        author_element = soup.find('span', class_='article__author')\n",
    "        return self._clean_text(author_element.get_text()) if author_element else \"\"\n",
    "\n",
    "    def _get_next_page_url(self, soup: BeautifulSoup) -> Optional[str]:\n",
    "        \"\"\"Extract the next page URL.\"\"\"\n",
    "        next_link = soup.find('a', attrs={'rel': 'next'})\n",
    "        if next_link:\n",
    "            return urljoin(self.base_url + \"/politiki\", next_link.get('href', ''))\n",
    "        return None\n",
    "\n",
    "    def extract_article_data(self, article_element) -> Optional[Dict]:\n",
    "        \"\"\"Extract data from an article teaser.\"\"\"\n",
    "        try:\n",
    "            # Find the link and get the relative URL\n",
    "            link = article_element.find('a')\n",
    "            if not link:\n",
    "                return None\n",
    "            \n",
    "            relative_url = link.get('href', '')\n",
    "            full_url = urljoin(self.base_url, relative_url)\n",
    "            \n",
    "            # Skip if we've already processed this URL\n",
    "            if full_url in self.seen_urls:\n",
    "                return None\n",
    "            \n",
    "            self.seen_urls.add(full_url)\n",
    "            \n",
    "            # Get article page content\n",
    "            article_soup = self._get_soup(full_url)\n",
    "            \n",
    "            # Extract title (from h3 or h4)\n",
    "            title_element = article_element.find(['h3', 'h4'])\n",
    "            title = self._clean_text(title_element.get_text()) if title_element else \"\"\n",
    "            \n",
    "            # Extract date\n",
    "            date_element = article_element.find('time', class_='default-date')\n",
    "            issue_date = self._parse_date(date_element)\n",
    "            \n",
    "            return {\n",
    "                \"site_url\": self.base_url + \"/politiki\",\n",
    "                \"issue_date\": issue_date,\n",
    "                \"author_name\": self._get_author(article_soup),\n",
    "                \"article_title\": title,\n",
    "                \"article_content\": self._extract_article_content(article_soup),\n",
    "                \"article_url\": full_url  # Adding URL to help identify duplicates\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_politics_page(self) -> List[Dict]:\n",
    "        \"\"\"Scrape articles from all pages until reaching 500 articles.\"\"\"\n",
    "        articles = []\n",
    "        current_url = f\"{self.base_url}/politiki\"\n",
    "        page_number = 0\n",
    "        \n",
    "        while current_url and self.article_count < self.MAX_ARTICLES:\n",
    "            print(f\"Scraping page {page_number + 1}...\")\n",
    "            soup = self._get_soup(current_url)\n",
    "            \n",
    "            # Find all article elements with different classes\n",
    "            article_elements = soup.find_all('article', class_=[\n",
    "                'squareb-teaser',\n",
    "                'squares-teaser',\n",
    "                'square-teaser'\n",
    "            ])\n",
    "            \n",
    "            for article_element in article_elements:\n",
    "                if self.article_count >= self.MAX_ARTICLES:\n",
    "                    break\n",
    "                    \n",
    "                article_data = self.extract_article_data(article_element)\n",
    "                if article_data:\n",
    "                    articles.append(article_data)\n",
    "                    self.article_count += 1\n",
    "                    print(f\"Scraped article {self.article_count}/{self.MAX_ARTICLES}\")\n",
    "                \n",
    "                # Add a small delay between requests\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Get next page URL\n",
    "            current_url = self._get_next_page_url(soup)\n",
    "            page_number += 1\n",
    "            \n",
    "            # Add a delay between pages\n",
    "            time.sleep(2)\n",
    "        \n",
    "        return articles\n",
    "\n",
    "def remove_duplicates(articles: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Remove duplicate articles based on URL and title.\"\"\"\n",
    "    seen_urls = set()\n",
    "    seen_titles = set()\n",
    "    unique_articles = []\n",
    "    \n",
    "    for article in articles:\n",
    "        url = article['article_url']\n",
    "        title = article['article_title']\n",
    "        \n",
    "        if url not in seen_urls and title not in seen_titles:\n",
    "            seen_urls.add(url)\n",
    "            seen_titles.add(title)\n",
    "            # Remove the article_url field as it was only used for deduplication\n",
    "            del article['article_url']\n",
    "            unique_articles.append(article)\n",
    "    \n",
    "    return unique_articles\n",
    "\n",
    "def save_articles_to_json(articles: List[Dict], output_folder: str) -> str:\n",
    "    \"\"\"Save unique articles to a single JSON file in the specified folder.\"\"\"\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Remove duplicates before saving\n",
    "    unique_articles = remove_duplicates(articles)\n",
    "    \n",
    "    # Create filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"efsyn_articles_{timestamp}.json\"\n",
    "    \n",
    "    # Create full file path\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "    \n",
    "    # Save the articles\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(unique_articles, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return filepath, len(unique_articles)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create scraper instance\n",
    "    scraper = EfsynScraper()\n",
    "    \n",
    "    # Scrape articles\n",
    "    articles = scraper.scrape_politics_page()\n",
    "    \n",
    "    # Specify your output folder and save the articles\n",
    "    output_folder = \"D:\\\\Web Scrapping Project\\\\efsyn_articles\"\n",
    "    saved_file, unique_count = save_articles_to_json(articles, output_folder)\n",
    "    \n",
    "    print(f\"\\nScraped {len(articles)} total articles\")\n",
    "    print(f\"Saved {unique_count} unique articles to: {saved_file}\")\n",
    "    print(f\"Removed {len(articles) - unique_count} duplicates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
