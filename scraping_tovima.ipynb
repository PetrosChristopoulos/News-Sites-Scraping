{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class ToVimaScraperException(Exception):\n",
    "    \"\"\"Custom exception for scraper errors\"\"\"\n",
    "    pass\n",
    "\n",
    "class ToVimaScraper:\n",
    "    def __init__(self, base_url, output_dir):\n",
    "        \"\"\"\n",
    "        Initialize the scraper with base URL and output directory\n",
    "        \n",
    "        Args:\n",
    "            base_url (str): The starting URL for scraping\n",
    "            output_dir (str): Directory to save the scraped articles\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.output_dir = output_dir\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        self.create_output_directory()\n",
    "\n",
    "    def create_output_directory(self):\n",
    "        \"\"\"Create the output directory if it doesn't exist\"\"\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def get_page_content(self, url):\n",
    "        \"\"\"\n",
    "        Fetch the content of a webpage\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL to fetch\n",
    "            \n",
    "        Returns:\n",
    "            BeautifulSoup object or None if failed\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.text, 'html.parser')\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching {url}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def extract_article_links(self, soup):\n",
    "        \"\"\"\n",
    "        Extract article links and titles from the page\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML of the page\n",
    "            \n",
    "        Returns:\n",
    "            list: List of tuples containing (title, url)\n",
    "        \"\"\"\n",
    "        articles = []\n",
    "        for link in soup.find_all('a', {'class': 'columns is-mobile is-multiline'}):\n",
    "            title = link.get('title')\n",
    "            url = link.get('href')\n",
    "            if title and url:\n",
    "                articles.append((title, url))\n",
    "        return articles\n",
    "\n",
    "    def get_next_page_url(self, soup):\n",
    "        \"\"\"\n",
    "        Find the URL of the next page\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML of the current page\n",
    "            \n",
    "        Returns:\n",
    "            str or None: URL of the next page or None if not found\n",
    "        \"\"\"\n",
    "        next_link = soup.find('a', title='Επόμενη Σελίδα')\n",
    "        return next_link.get('href') if next_link else None\n",
    "\n",
    "    def extract_article_text(self, soup):\n",
    "        \"\"\"\n",
    "        Extract the plain text content from an article\n",
    "        \n",
    "        Args:\n",
    "            soup (BeautifulSoup): Parsed HTML of the article\n",
    "            \n",
    "        Returns:\n",
    "            str: Plain text content of the article\n",
    "        \"\"\"\n",
    "        article_div = soup.find('div', {'class': 'post-body main-content pos-rel article-wrapper'})\n",
    "        if not article_div:\n",
    "            return None\n",
    "\n",
    "        # Remove unwanted elements\n",
    "        for element in article_div.find_all(['script', 'style', 'iframe', 'div', 'figure']):\n",
    "            element.decompose()\n",
    "\n",
    "        # Extract text from paragraphs\n",
    "        paragraphs = article_div.find_all('p')\n",
    "        text = '\\n\\n'.join(p.get_text().strip() for p in paragraphs)\n",
    "        \n",
    "        # Clean up the text\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text)  # Remove excessive newlines\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove excessive whitespace\n",
    "        \n",
    "        return text.strip()\n",
    "\n",
    "    def save_article(self, title, content, index):\n",
    "        \"\"\"\n",
    "        Save article content to a file\n",
    "        \n",
    "        Args:\n",
    "            title (str): Article title\n",
    "            content (str): Article content\n",
    "            index (int): Article index for filename\n",
    "        \"\"\"\n",
    "        if not content:\n",
    "            return\n",
    "\n",
    "        # Create a safe filename from the title\n",
    "        safe_title = re.sub(r'[^\\w\\s-]', '', title)\n",
    "        safe_title = re.sub(r'\\s+', '_', safe_title)\n",
    "        filename = f\"{index:03d}_{safe_title[:50]}.txt\"\n",
    "        \n",
    "        filepath = os.path.join(self.output_dir, filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Title: {title}\\n\\n\")\n",
    "            f.write(content)\n",
    "\n",
    "    def scrape_articles(self, max_articles=100):\n",
    "        \"\"\"\n",
    "        Main method to scrape articles\n",
    "        \n",
    "        Args:\n",
    "            max_articles (int): Maximum number of articles to scrape\n",
    "        \"\"\"\n",
    "        current_url = self.base_url\n",
    "        article_count = 0\n",
    "        \n",
    "        while current_url and article_count < max_articles:\n",
    "            print(f\"Processing page: {current_url}\")\n",
    "            \n",
    "            # Get the page content\n",
    "            soup = self.get_page_content(current_url)\n",
    "            if not soup:\n",
    "                break\n",
    "\n",
    "            # Extract article links\n",
    "            articles = self.extract_article_links(soup)\n",
    "            \n",
    "            # Process each article\n",
    "            for title, article_url in articles:\n",
    "                if article_count >= max_articles:\n",
    "                    break\n",
    "                    \n",
    "                print(f\"Scraping article {article_count + 1}: {title}\")\n",
    "                \n",
    "                # Get article content\n",
    "                article_soup = self.get_page_content(article_url)\n",
    "                if article_soup:\n",
    "                    content = self.extract_article_text(article_soup)\n",
    "                    if content:\n",
    "                        self.save_article(title, content, article_count)\n",
    "                        article_count += 1\n",
    "                \n",
    "                # Be nice to the server\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Get next page URL\n",
    "            current_url = self.get_next_page_url(soup)\n",
    "            \n",
    "            # Be nice to the server between pages\n",
    "            time.sleep(2)\n",
    "\n",
    "        print(f\"Finished scraping {article_count} articles\")\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_URL = \"https://www.tovima.gr/category/politics/\"\n",
    "    OUTPUT_DIR = \"D:\\\\Web Scrapping Project\\\\tovima_articles\"\n",
    "    \n",
    "    scraper = ToVimaScraper(BASE_URL, OUTPUT_DIR)\n",
    "    scraper.scrape_articles(max_articles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The output of the code is:\n",
    "\n",
    "Processing page: https://www.tovima.gr/category/politics/\n",
    "Scraping article 1: ΣΥΡΙΖΑ – Κασσελάκης: Στα μαχαίρια για συνέδριο, νοθεία, μητρώο, δεοντολογία και ΟΜ\n",
    "Scraping article 2: Κακλαμάνης για Μητσοτάκη – Σαμαρά: Σηκώνεις το τηλέφωνο και λες «έλα να το λύσουμε»\n",
    "Scraping article 3: ΣΥΡΙΖΑ: Ο Μητσοτάκης δεν μπορεί να ξεγλιστρήσει από τη χυδαιότητα\n",
    "Scraping article 4: Τζάκρη: Ο Κασσελάκης δεν έδιωξε και δεν θα διώξει κανέναν\n",
    "Scraping article 5: Βουλή: Οσα έγιναν χθες – Σε τρία μέτωπα η επίθεση Μητσοτάκη\n",
    "Scraping article 6: Εκλογές ΣΥΡΙΖΑ: Λήξη διορίας – Ούτε βήμα πίσω ο Κασσελάκης\n",
    "Scraping article 7: Στέφανος Κασσελάκης: Άνοιξαν οι πόρτες των γραφείων του – Καπνογόνα στην άφιξη\n",
    "Scraping article 8: ΣΥΡΙΖΑ κατά Μητσοτάκη: «Εκτροπή και ύβρη του πρωθυπουργού των σκανδάλων»\n",
    "Scraping article 9: Αγριεύει η κόντρα Μητσοτάκη-Σαμαρά: «Να ασχοληθούμε με τα σοβαρά στα σύνορά μας»\n",
    "Scraping article 10: Γαλάζιες αντιθέσεις απέναντι σε Παππά – Ο Μητσοτάκης έφυγε, ο Σαμαράς χαιρέτησε\n",
    "Scraping article 11: Νίκος Παππάς: Η απάντηση στην κίνηση Μητσοτάκη – Κακομαθημένο παιδί\n",
    "Scraping article 12: Ανδρουλάκης σε Μητσοτάκη: «Οι μέρες της παντοδυναμίας σας ανήκουν στο παρελθόν»\n",
    "Processing page: https://www.tovima.gr/category/politics/page/2/\n",
    "Scraping article 13: Παππάς στη Βουλή για τις φωτιές: Τι από αυτά είναι προϊόν φαντασίας;\n",
    "Scraping article 14: Βουλή: Επίθεση Μητσοτάκη σε Παππά – «Δεν αναγνωρίζω τον 13-0» – Πυρά και κατά Ανδρουλάκη\n",
    "Scraping article 15: Μητσοτάκης: «Ήταν η πιο δύσκολη αντιπυρική περίοδος των τελευταίων 40 ετών»\n",
    "Scraping article 16: Βουλή Live – Μητσοτάκης: Τo 112 σώζει ζωές – Οι ομιλίες στη Βουλή για τις φωτιές\n",
    "Scraping article 17: ΠαΣοΚ: Πώς ο Μάντζος έσωσε τη Λιακούλη\n",
    "Scraping article 18: Οι έμμεσες οδηγίες Τσίπρα για νέο κόμμα\n",
    "Scraping article 19: ΠαΣοΚ: Τι ζήτησε ο Ανδρουλάκης στη συνεδρίαση της «Στρογγυλής Τραπέζης»\n",
    "Scraping article 20: Σύγκρουση Μητσοτάκη-Ανδρουλάκη στη Βουλή: Οι κόντρες στο παρελθόν και οι φαρμακερές ατάκες\n",
    "Scraping article 21: Τσίπρας: Χτυπάω καμπανάκι – Η χώρα χρειάζεται μεγάλο αναπτυξιακό σοκ\n",
    "Scraping article 22: Ολοκληρώθηκε η ενημέρωση του Γεραπετρίτη στους γαλάζιους βουλευτές\n",
    "Scraping article 23: Κυριάκος Μητσοτάκης σε Αντόνιο Κόστα: «Σε θεωρούμε έναν από εμάς»\n",
    "Scraping article 24: Η Λιακούλη έδωσε τη σκυτάλη στον Μπιάγκη – Γεύμα για δύο στη Βουλή\n",
    "Scraping article 25: Ο Γεραπετρίτης ενημερώνει τους γαλάζιους βουλευτές – Τα γλυκά που κέρασε η Ντόρα\n",
    "Scraping article 26: Πρώτη του ΠαΣοΚ χωρίς Γερουλάνο – «Αιχμές» Άννας για τον Δούκα\n",
    "Scraping article 27: Κασσελάκης: Παράτυπη η ψήφος Βερναρδάκη – Να δώσει εξηγήσεις η Σβίγκου\n",
    "Scraping article 28: Νέα Δημοκρατία: Η απάντηση για το πρόστιμο των 40.000 ευρώ\n",
    "Scraping article 29: Βουλή: Ο Λιβάνιος δεν δέχθηκε την τροπολογία του ΠαΣοΚ – Σύγκρουση Στίγκα με Δουδωνή\n",
    "Scraping article 30: Φάμελλος: Στήριξη από Ιωακειμίδη – «Με τον Σωκράτη, αυτό θα κάνουμε σλόγκαν»\n",
    "Scraping article 31: Πρόστιμο στη ΝΔ για τα αρχεία – Αφορμή τα Ασημακοπούλου Leaks\n",
    "Scraping article 32: Εκλογές ΣΥΡΙΖΑ: Ο Κασσελάκης ανοίγει τα νέα γραφεία του στο κοινό\n",
    "Processing page: https://www.tovima.gr/category/politics/page/3/\n",
    "Scraping article 33: ΟΠΕΚΕΠΕ: Το λάθος, τα 50 εκ ευρώ και το εκρηκτικό κλίμα στην ύπαιθρο\n",
    "Scraping article 34: Συνέδριο ΣΥΡΙΖΑ: Ο «πόλεμος» της 25ης Οκτωβρίου – Πώς επηρεάζεται ο Κασσελάκης\n",
    "Scraping article 35: «Αφωνος» για 10 μέρες ο Παύλος Γερουλάνος – Ο λόγος\n",
    "Scraping article 36: ΠαΣοΚ: Οι ενισχυμένοι των ανακοινώσεων Ανδρουλάκη -Γκρίνιες κι αντιδράσεις \n",
    "Scraping article 37: Ινστιτούτο Αλέξη Τσίπρα: Η εκδήλωση και η παρέμβαση του πρώην πρωθυπουργού\n",
    "Scraping article 38: Γιατί «σφάζονται» η Λατινοπούλου με τον Βελόπουλο – Ο πόλεμος στα δεξιά της ΝΔ\n",
    "Scraping article 39: ΠαΣοΚ: Οι τρεις γυναίκες που ξάφνιασαν – Το προφίλ των Πλέσια, Σαμαρά και Σολωμού\n",
    "Scraping article 40: Ελεονώρα Μελέτη σε ΕΕ: Οι κίνδυνοι των παιδιών στο διαδίκτυο\n",
    "Scraping article 41: Η στρατηγική της ΝΔ για Λατινοπούλου, Βελόπουλο\n",
    "Scraping article 42: Δημοσκόπηση ALCO: Άνοδος για το ΠαΣοΚ – Συνεχίζεται η κατηφόρα του ΣΥΡΙΖΑ\n",
    "Scraping article 43: Υποκλοπές: Ευρωπαϊκή Επιτροπή και ΕΔΔΑ προστατεύουν την ελευθερία του Tύπου από την αγωγή Δημητριάδη\n",
    "Scraping article 44: ΣΥΡΙΖΑ – Νίκος Παππάς: 4 απαντήσεις στην κυβέρνηση για την οικονομία – Ας συναντηθεί με την αλήθεια\n",
    "Scraping article 45: ΠαΣοΚ: Οι αιχμές Δούκα για τις επιλογές Ανδρουλάκη – Τι αναφέρουν κύκλοι του Δημάρχου Αθηναίων\n",
    "Scraping article 46: Κασσελάκης: Τα νέα γραφεία του στον Ταύρο\n",
    "Scraping article 47: Ελάχιστα ρεαλιστική πολιτικά η ενίσχυση\n",
    "Scraping article 48: ΠαΣοΚ: Οι αλλαγές Ανδρουλάκη – Οι ρόλοι σε Δούκα, Γερουλάνο, Διαμαντοπούλου\n",
    "Scraping article 49: ΣΥΡΙΖΑ: Ο Φάμελλος ζητά η παράσταση «18/9» για τον Π. Φύσσα να μπει στα σχολεία\n",
    "Scraping article 50: ΣΥΡΙΖΑ: Ο αλγόριθμος του χάους – Οι ημερομηνίες κλειδιά μέχρι το Συνέδριο\n",
    "Scraping article 51: Ελληνοτουρκικά: «Γεράκια» και «περιστέρια» στο Αιγαίο – Τα ήρεμα νερά και τα υπόγεια ρεύματα\n",
    "Scraping article 52: Νέα Αριστερά:  Η ιδρυτική πράξη, η αυτοκριτική, η κριτική σε ΣΥΡΙΖΑ – Κασσελάκη\n",
    "Processing page: https://www.tovima.gr/category/politics/page/4/\n",
    "Scraping article 53: ΣΥΡΙΖΑ: Οι εκτιμήσεις για τους βουλευτές που στηρίζουν τον Στέφανο Κασσελάκη\n",
    "Scraping article 54: ΠαΣοΚ: Τα ονόματα που θα ανακοινώσει ο Νίκος Ανδρουλάκης και οι θέσεις που θα πάρουν\n",
    "Scraping article 55: «Σετ ανακοινώσεων» για πρόσωπα και νέους ρόλους στο ΠαΣοΚ\n",
    "Scraping article 56: Η υψηλή τέχνη της σάτιρας\n",
    "Scraping article 57: Φώφη Γεννηματά: Μνημόσυνο για τα 3 χρόνια από τον θάνατό της [Βίντεο, Εικόνες]\n",
    "Scraping article 58: Κασσελάκης: Νοίκιασε γραφεία για την εκστρατεία του – «Κάποιοι βιάστηκαν να με διώξουν νύχτα»\n",
    "Scraping article 59: Βάσω Παπανδρέου: Μαχητική, χαρισματική, ανεξάρτητη\n",
    "Scraping article 60: Παντρεύτηκαν Δούκας και Πολυτάνου – Ποιοι βρέθηκαν στο γάμο (ΦΩΤΟΓΡΑΦΙΕΣ ΚΑΙ ΒΙΝΤΕΟ)\n",
    "Scraping article 61: Η ομιλία του Μάξιμου Χαρακόπουλου στο επιστημονικό συνέδριο για τον Μικρασιατικό Ελληνισμό\n",
    "Scraping article 62: ΣΥΡΙΖΑ: Εξ αποστάσεως καρφιά Κασσελάκη – Φάμελλου – Φαραντούρη\n",
    "Scraping article 63: Δουδωνής σε Σκέρτσο: «Ανεύθυνη είναι η επιλεκτική χρήση των στατιστικών»\n",
    "Scraping article 64: ΠαΣοΚ: Τηλεφώνημα Ανδρουλάκη σε Διαμαντοπούλου, το ραντεβού με Γερουλάνο\n",
    "Scraping article 65: Εκλογές ΣΥΡΙΖΑ: Κόμμα διασπασμένο στην κορυφή αλλά και στη βάση\n",
    "Scraping article 66: Φρέντης Μπελέρης – Σε πρώτο Ενικό: «Όταν έφτασα στην Ελλάδα ήταν σαν να ξαναγεννήθηκα»\n",
    "Scraping article 67: Νέα Δημοκρατία: Τι απέδωσε το γαλάζιο μασάζ – Πόσο άλλαξε το κλίμα στη ΚΟ\n",
    "Scraping article 68: ΣΥΡΙΖΑ: Μέλη της ΚΕ παραπέμπουν στην Επιτροπή Δεοντολογίας Γεροβασίλη, Ζαχαριάδη και Γκλέτσο\n",
    "Scraping article 69: ΣΥΡΙΖΑ: Φιλαλήθης η κυβέρνηση του μπαζώματος;\n",
    "Scraping article 70: ΣΥΡΙΖΑ: «Καταφανώς ψευδεπίγραφο το φιλελεύθερο προφίλ Μητσοτάκη»\n",
    "Scraping article 71: Ο άγνωστος καυγάς της Ζωής Κωνσταντοπούλου με τη Ντόρα Μπακογιάννη\n",
    "Scraping article 72: Οικονόμου: Εμπάθεια από στελέχη κατά Κασσελάκη\n",
    "Processing page: https://www.tovima.gr/category/politics/page/5/\n",
    "Scraping article 73: Εκλογές ΣΥΡΙΖΑ: Απορίες Κασσελάκη, αιχμές Φάμελλου – Πολάκη, «αποστάτες» και «μπουζουξίδικο»\n",
    "Scraping article 74: Νίκος Ανδρουλάκης: «18 Οκτωβρίου 1981, ραντεβού με την Ιστορία»\n",
    "Scraping article 75: Κασσελάκης: «Συνέδριο σε κλειστό νυχτερινό κέντρο» – Τα 4 ερωτήματα\n",
    "Scraping article 76: Ο Ανδρουλάκης σχηματίζει σκιώδη κυβέρνηση – Τα πρόσωπα-κλειδιά\n",
    "Scraping article 77: Μητσοτάκης: Πού ήταν οι υπερπατριώτες όταν προστατεύσαμε τα σύνορα στον Έβρο;\n",
    "Scraping article 78: Κασσελάκης: «Είναι δυνατόν να βλέπουμε ακόμα φασισμό στην χώρα μας και αντιδημοκρατικές πρακτικές;»\n",
    "Scraping article 79: Δημοσκόπηση GPO: Πόσο ανέβηκε το ΠαΣοΚ μετά τη νίκη Ανδρουλάκη – Υποχωρεί ο ΣΥΡΙΖΑ\n",
    "Scraping article 80: ΣΥΡΙΖΑ: Καταδικάζεται, δεν παραπέμπεται ο Κασσελάκης – Σκληρά λόγια στην ΠΓ\n",
    "Scraping article 81: Γιώργος Παπανδρέου για Βάσω Παπανδρέου: «Άφησε παντού το ιδιαίτερο, βαθύ αποτύπωμά της»\n",
    "Scraping article 82: ΠαΣοΚ: Η τροπολογία που κατέθεσε για τους Σπαρτιάτες – Η αλλαγή που ζητά\n",
    "Scraping article 83: Βάσω Παπανδρέου: Η άλλη πλευρά της Σιδηράς Κυρίας – «Η Βάσω συμφώνησε;»\n",
    "Scraping article 84: Άγρια κόντρα Σπαρτιατών-ΠαΣοΚ: «Έχετε κατακλέψει τον κόσμο» – «Είστε η συνέχεια της ΧΑ»\n",
    "Scraping article 85: ΣΥΡΙΖΑ: Εμφυλιοπολεμικό το κλίμα στην Πολιτική Γραμματεία – Σκληρά λόγια και διαφωνίες\n",
    "Scraping article 86: Μαρινάκης για πρωτοβουλία ΠαΣοΚ για Σπαρτιάτες: Μας έχει μπερδέψει\n",
    "Scraping article 87: Όταν η Βάσω Παπανδρέου πήρε το όπλο της στην κρίσιμη στιγμή για το ΠαΣοΚ\n",
    "Scraping article 88: Κυριάκος Μητσοτάκης για Βάσω Παπανδρέου: «Άφησε το δικό της αποτύπωμα»\n",
    "Scraping article 89: Βάσω Παπανδρέου – Το «ναι» ήταν «ναι» και το «όχι» ήταν «όχι»\n",
    "Scraping article 90: Ανδρουλάκης για Βάσω Παπανδρέου: «Υπηρέτησε χωρίς συμβιβασμούς τις πολιτικές θέσεις της»\n",
    "Scraping article 91: Η Βάσω Παπανδρέου μέσα από εικόνες της εποχής ΠαΣοΚ\n",
    "Scraping article 92: Σημίτης για Βάσω Παπανδρέου: «Ήταν μια άξια γυναίκα, τίμησε τις θέσεις που ανέλαβε»\n",
    "Processing page: https://www.tovima.gr/category/politics/page/6/\n",
    "Scraping article 93: Νέο «χτύπημα» Κακλαμάνη για το Χρηματιστήριο Ενέργειας\n",
    "Scraping article 94: Ο πολιτικός κόσμος αποχαιρετά τη Βάσω Παπανδρέου – Η κίνηση Τασούλα\n",
    "Scraping article 95: Καυγάς Πολάκη με Γεωργιάδη στη Βουλή – Ήρθη η ασυλία του βουλευτή του ΣΥΡΙΖΑ\n",
    "Scraping article 96: Πέθανε η Βάσω Παπανδρέου\n",
    "Scraping article 97: ΣΥΡΙΖΑ – Κασσελάκης: Οριακή η κατάσταση πριν από την ΠΓ – Βουλευτές στην έξοδο\n",
    "Scraping article 98: Μητσοτάκης για μεταναστευτικό: Λείπει μία αποτελεσματική πολιτική επιστροφών από την ΕΕ\n",
    "Scraping article 99: Γιατί ο Κασιδιάρης βιάζεται να γίνει η δίκη των Σπαρτιατών\n",
    "Scraping article 100: Τι κρύβει η κόντρα της Λατινοπούλου με την κυβέρνηση\n",
    "Finished scraping 100 articles\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
